{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a7c96c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def view_random_image(target_dir, target_class):\n",
    "  target_folder = target_dir + target_class\n",
    "  random_image = random.sample(os.listdir(target_folder), 1)\n",
    "\n",
    "  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
    "  plt.imshow(img)\n",
    "  plt.title(target_class)\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "  print(f\"Ukuran Gambar:{img.shape}\")\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15cbb617",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e78693",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39435e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"dataset tumbuhan/DATASET TANAMAN HERBAL/Data Training\"\n",
    "test_dir = \"dataset tumbuhan/DATASET TANAMAN HERBAL/Data Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "905f6a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 10 classes.\n",
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               batch_size = 16,\n",
    "                                               target_size = (450,550),\n",
    "                                               class_mode = \"categorical\",\n",
    "                                               seed = 46\n",
    "                                              )\n",
    "\n",
    "valid_data = valid_datagen.flow_from_directory(test_dir,\n",
    "                                               batch_size = 16,\n",
    "                                               target_size = (450,550),\n",
    "                                               class_mode = \"categorical\",\n",
    "                                               seed = 46\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca0ffc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentasi data\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,  \n",
    "                                   horizontal_flip = True\n",
    "                                  )\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e86b3871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_augmented = train_datagen.flow_from_directory(train_dir,\n",
    "                                                         batch_size = 16,\n",
    "                                                         target_size = (450,550),\n",
    "                                                         class_mode = 'categorical',\n",
    "                                                         shuffle = True\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3807f27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential([\n",
    "    Conv2D(10,3, activation = 'relu'),\n",
    "    MaxPool2D(2),\n",
    "    Conv2D(10, 3, activation = 'relu'),\n",
    "    MaxPool2D(2),\n",
    "    Flatten(),\n",
    "    Dense(10, activation = \"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "736b9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss= \"categorical_crossentropy\",\n",
    "                optimizer = Adam(),\n",
    "                metrics = ['accuracy']\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "721c1c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 270s 5s/step - loss: 2.6474 - accuracy: 0.3300 - val_loss: 1.8504 - val_accuracy: 0.4300\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 246s 5s/step - loss: 0.6952 - accuracy: 0.8138 - val_loss: 1.7990 - val_accuracy: 0.5300\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 243s 5s/step - loss: 0.2793 - accuracy: 0.9337 - val_loss: 1.6496 - val_accuracy: 0.6050\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 257s 5s/step - loss: 0.0744 - accuracy: 0.9850 - val_loss: 1.6621 - val_accuracy: 0.6250\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 267s 5s/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 1.7350 - val_accuracy: 0.6700\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 229s 5s/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.7471 - val_accuracy: 0.6700\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 202s 4s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.7963 - val_accuracy: 0.6650\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 208s 4s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.8504 - val_accuracy: 0.6650\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 221s 4s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9027 - val_accuracy: 0.6700\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 209s 4s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9431 - val_accuracy: 0.6700\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(\n",
    "    train_data,\n",
    "    epochs = 10,\n",
    "    validation_data = valid_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71158dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
